\documentclass[]{article}
\usepackage[a4paper, total={6.5in, 10.5in}]{geometry}%6
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{longtable}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{float}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    frame=single
}

% Title Page
\title{Homework1, Algoritmi su Grafi}
\author{Enrico Cancelli, \textit{matr.} 1237293\\
		Alessandro Pegoraro, \textit{matr.} 1240466}


\begin{document}
\maketitle \medskip

\section{Introduzione}
Lo scopo di questo progetto è l'implementazione e l'analisi di 4 algoritmi di ricerca per il \textit{Minimum Spanning Tree} (in seguito solo MST) di un grafo pesato e non diretto.\\
Questi algoritmi sono:
\begin{itemize}
	\item Algoritmo di Prim
	\item Algoritmo di Kruskal (implementazione naive DFS)
	\item Algoritmo di Kruskal (implementazione naive BFS)
	\item Algoritmo di Kruskal con struttura dati \textit{Union-Find}
\end{itemize}
\subsection{Pseudocodice}
Come riferimento per l'implementazione degli algoritmi è stato preso il seguente pseudo codice spiegato a lezione:\\
\begin{algorithm}[H]
	\SetAlgoLined
	\DontPrintSemicolon
	\KwIn{Graph G, vertex s}
	\KwResult{Graph of a MST}
	\For{each u $\in$ V}{
		key[u] $\gets$ +$\infty$\;
		$\pi$[u] $\gets$ NULL\;
	}
	key[s] $\gets$ 0\;
	Q $\gets$ V\;
	\While{Q $\neq$ Ø}{
		u $\gets$ extractMin(Q)\;
		\For{each v adjacent to u}{
			\If{v $\in$ Q and w(u,v) $<$ key[v]}{
				$\pi$[v] $\gets$ u\;
				key[v] $\gets$ w(u,v)\;
			}
		}
	}
	return A\;
	\caption{Prim}
\end{algorithm}

\begin{algorithm}[H]
	\SetAlgoLined
	\DontPrintSemicolon
	\KwIn{Graph G}
	\KwResult{Graph of a MST}
	A = Ø\;
	sort edges of G by cost\;
	\For{each edge e, in nondecreasing order of cost}{
		\If{A $\cup$ {e} is acyclic}{
			A = A $\cup$ {e}\;
		}
	}
	return A\;
	\caption{Kruskal Naive}
\end{algorithm}

\begin{algorithm}[H]
	\SetAlgoLined
	\DontPrintSemicolon
	\KwIn{Graph G}
	\KwResult{Graph of a MST}
	A = Ø\;
	U = initialize(V)\;
	sort edges of E by cost\;
	\For{each edge e=(v,w), in nondecreasing order of cost}{
		\If{Find(U,v) $\neq$ Find(U,w)}{
			A = A $\cup$ {(v,w)}\;
			Union(U,v,w)
		}
	}
	return A\;
	\caption{Kruskal Union-Find}
\end{algorithm}
\subsection{Struttura del progetto}
Nelle successive sezioni descriveremo in dettaglio l'implementazione di questi algoritmi e delle relative strutture dati di supporto e li testeremo su un dataset fornito generato randomicamente, analizzando i risultati ottenuti e le performance in termini di tempo d'esecuzione e spazio allocato in memoria.\\
I test saranno condotti su grafi non necessariamente semplici (quindi con la possibile presenza di \textit{self loops} e archi multipli tra due nodi) e con pesi non necessariamente positivi.\\
Abbiamo scelto di implementare tali algoritmi utilizzando il linguaggio \textit{C++17} per motivi di efficienza e per potere, allo stesso tempo, utilizzare astrazioni tipiche dei linguaggi ad oggetti rendendo il codice prodotto più modulare tramite l'utilizzo di classi templetizzate.
\section{Implementazione}
In questa sezione verranno esposte e adeguatamente motivate le scelte implementative adottate durante lo sviluppo. L'intero progetto è stato realizzato facendo il più possibile uso di codice generico (template di classe per le strutture dati di supporto e template di funzione per gli algoritmi).\\
Infine verrà data una spiegazione dettagliata sulla struttura del codice realizzato ed eventuali note per la compilazione.
\subsection{Parser}
Considerando che il formato dei grafi di esempio nel dataset è standardizzato nel seguente modo:
\begin{verbatim}
[numero_di_vertici] [numero_di_archi] 
[un_vertice_arco_1] [altro_vertice_arco_1] [peso_arco_1] 
[un_vertice_arco_2] [altro_vertice_arco_2] [peso_arco_2] 
... 
[un_vertice_arco_N] [altro_vertice_arco_N] [peso_arco_N]
\end{verbatim}
abbiamo implementato una classe \textbf{Parser} che permette di decodificare solo i file nel formato descritto.\\
Dato che utilizziamo i nodi come indici nelle strutture dati e nei file di esempio i vertici cominciano dall'intero 1, all'interno delle funzioni di decodifica diminuiamo tutti i nodi di un unità in modo da non sprecare l'indice 0, ciò comunque non comporta alcuna differenza alle relazioni tra i nodi e al risultato finale.
\subsection{Strutture dati}
\subsubsection{MinHeap}
Nella classe \textbf{Minheap$<$W$>$} è stata implementata la struttura dati omonima, adeguatamente modificata ed adattata per essere utilizzata nel caso specifico dell'algoritmo di Prim allo scopo di minimizzare le differenze tra codice C++ e pseudocodice, cercando di massimizzarne l'efficienza.\smallskip
\begin{flushleft}
Internamente un MinHeap è una lista di coppie chiave-valore dove il primo elemento rappresenta il valore di tipo \textbf{W} utilizzato per l'ordinamento e il secondo il numero intero che identifica un nodo.\\
Il nodo in posizione 0 rappresenta la radice dell'albero binario e dato un nodo in posizione $i$, il figlio sinistro è rappresentato dal noto in posizione $2i+1$, il sinistro dal nodo in posizione $2i+2$ e il padre dal nodo in posizione$\lfloor \frac{i-1}{2}\rfloor$.\\
Essendo tutti i nodi inseriti al momento della creazione della struttura dati e mai eliminati se non grazie al metodo \verb|extractMin|, l'operazione di inserimento di un nuovo nodo non è stata implementata.
L'ordinamento durante la costruzione di MinHeap è effettuato grazie al \textit{metodo di costruzione di Floyd} implementato nel metodo \verb|min_heapify|. Questo metodo, oltre a non necessitare dell'operatore di inserimento, ha il vantaggio di essere più efficiente della classica costruzione (complessità $O(n)$ anzichè $O(n\cdot\log n)$).\\\smallskip
Essendo necessario, durante l'esecuzione dell'algoritmo di Prim, aggiornare il valore della chiave per alcuni vertici all'interno di Minheap, la struttura dati mantiene una lista di interi \verb|track| che tiene traccia della posizione di ciascun vertice all'interno dell'albero (i.e. $track[i]=\begin{cases}
-1 & \text{se } i \notin H\\
\text{\textit{pos. di i}} & \text{se } i \in H\\
\end{cases}$ ).\\
Questa lista ci permette inoltre di implementare in maniera naturale l'operatore \verb|exists| che controlla se un vertice è già stato estratto dal MinHeap.
Essendo l'operazione di aggiornamento effettuata solo in caso il nuovo valore sia minore di quello corrente, il metodo \verb|decreaseUpdate| utilizza la lista \verb|track| per individuare il nodo all'interno dell'heap, ne aggiorna il peso ed effettua un'operazione di \textit{up-heap} (implementata dal metodo privato \verb|push_up|).
\end{flushleft}
\subsubsection{Union-Find (Disjoint-set)}
Nella classe \textbf{UnionFind} è stata implementata la struttura dati per l'algoritmo Kruskal Union-Find, utilizzando come base un vettore di coppie di interi in cui ogni indice rappresenta un nodo.\\
La coppia in posizione $i$ all'interno della lista è $<parent(i), size(i)>$, dove $parent(i)$ è il padre del nodo all'interno dell'albero che rappresenta il set a cui $i$ appartiene o, in caso $i$ sia radice, se stesso. Invece $size(i)$ rappresenta la dimensione dell'albero radicato in $i$, la quale viene utilizzata come criterio di merging durante le operazioni di unione.\\
I metodi \verb|find| e \verb|unite| rappresentano rispettivamente le operazioni di ricerca e unione. Il secondo metodo inoltre si occupa di aggiornare ad ogni invocazione i valori di $size(i)$.
\subsection{Strutture per la rappresentazione di grafi}
\subsubsection{Edge}
Per rappresentare un lato composto dai due nodi adiacenti e il peso associato abbiamo creato la classe templetizzata \textbf{Edge$<$W$>$}, con \textbf{W} tipo del peso.\\
Nella classe abbiamo ridefinito l'operatore di relazione \textbf{$<$} in modo tale che confronti il peso tra due lati, dato che rappresentiamo l'insieme di lati del grafo \textbf{E} utilizzando un \verb|std::vector|$<$\textbf{Edge}$>$ per poter ordinare i lati in ordine crescente facendo uso della funzione \verb|std::sort()| che prende in input le posizioni estreme del vettore e utilizza l'operatore \textbf{$<$} per l'ordinamento.
\subsubsection{Adjacency List}
\begin{flushleft}
Per rappresentare il grafo abbiamo utilizzato una lista di adiacenza implementata dalla classe \textbf{AdjacencyList$<$W$>$}, con \textbf{W} tipo del peso dei lati.\\
Dato che i grafi possedevano un numero di lati nettamente inferiore al quadrato del numero dei nodi abbiamo preferito ridurre lo spazio occupato dalla rappresentazione scegliendo una struttura densa come la lista di adiacenza invece di una struttura sparsa come la matrice di adiacenza.\\
La classe è composta da un \verb|std::vector| in cui ogni indice rappresenta un nodo, e ogni elemento è a sua volta un \verb|std::vector| di coppie \verb|std::pair| nella quale il primo membro è un intero che rappresenta un nodo adiacente all'indice, mentre il secondo elemento è il peso associato al lato che collega i due nodi.\\

Per verificare se due nodi sono connessi nel grafo abbiamo implementato la funzione ricorsiva \verb|DFS(int v,int w)|:
\lstset{language=c++, style=mystyle}
\lstinputlisting[language=c++]{DFS.cpp}
La quale internamente chiama la funzione privata \verb|DFS_inside(int v, int w, bool L[])| la cui implementazione è identica a \verb|DFS| con la differenza che il vettore \verb|L| non viene istanziato ma è fornito da \verb|DFS|.\\
In \verb|L| ogni indice rappresenta un nodo e ogni elemento indica se quel nodo è stato già visitato durante la ricerca.\\
Abbiamo implementato anche la funzione \verb|BFS(int v,int w)| in forma iterativa per confrontare la velocità tra i due algoritmi in \textbf{Kruskal naive}:
\lstset{language=c++, style=mystyle}
\lstinputlisting[language=c++]{BFS.cpp}
\end{flushleft}
Nella classe abbiamo inoltre implementato  \verb|get_nodes()| e \verb|get_edges()| per ritornare rispettivamente il numero di nodi e di lati in tempo costante, ciò è possibile dato che la prima funzione ritorna la size del \verb|std::vector|, mentre per la seconda funzione abbiamo predisposto una variabile per tener conto del numero di lati durante la costruzione.\\
In quanto il calcolo del peso totale del MST non era presente negli algoritmi ma è possibile calcolarlo nel \verb|main| la funzione \verb|total_weight()| non è stata ottimizzata predisponendo una variabile ma semplicemente cicla tutta la \textbf{AdjacencyList$<$W$>$} sommando i pesi e divide il risultato a metà.
\lstset{language=c++, style=mystyle}
\lstinputlisting[language=c++]{total_weight.cpp}
\newpage

\subsection{Algoritmi}
\subsubsection{Prim}
\begin{flushleft}
	La nostra implementazione presente nel file \verb|algorithms\prim.h| è la seguente:
	
	\lstset{language=c++, style=mystyle}
	\lstinputlisting[language=c++]{prim.cpp}
	
	\textbf{Note implementative:}
	
	\medskip
	Per la creazione e inizializzazione delle liste \textit{key} e $\pi$:
	\lstset{language=c++, style=mystyle,backgroundcolor=\color{white}, firstnumber=1}  	 	
	\begin{lstlisting}[mathescape=true]
	for each u $\in$ V {
		key[u] $\gets$ +$\infty$;
		$\pi$[u] $\gets$ NULL;
	}
	key[s] $\gets$ 0;\end{lstlisting}
	Sono state utilizzate rispettivamente una lista di interi \verb|pi| e una lista di coppie chiave-nodo associato \verb|V| in modo da utilizzare lo stesso contenitore per mantenere il valore di \textit{key} e come lista di input per il MinHeap $Q$.
	\lstset{language=c++, style=mystyle, firstnumber=2}  	 	
	\begin{lstlisting}[mathescape=true]
	unsigned int n_vec = G.get_nodes();
	std::vector<std::pair<W, int>> V(n_vec);
	std::vector<int> pi(n_vec);\end{lstlisting}
	Inizialmente \textit{key} e $\pi$ sono inizializzate utilizzando \verb|INT_MAX| al posto di $+\infty$ e $-1$ al posto di \verb|null|.
	\lstset{language=c++, style=mystyle, firstnumber=5}  	 	
	\begin{lstlisting}[mathescape=true]
	V[0] = std::make_pair(0, 0);
	pi[0] = -1;
	for(unsigned int i = 1; i < n_vec; ++i){
		V[i] = std::make_pair(INT_MAX, i);
		pi[i] = -1;
	}\end{lstlisting}
	
	Per la guardia del ciclo più interno:
	\lstset{language=c++, style=mystyle,backgroundcolor=\color{white}, firstnumber=9}  	 	
	\begin{lstlisting}[mathescape=true]
	for each v adjacent to u {\end{lstlisting}
	Viene utilizzata la lista di adiacenza per estrarre il vettore di coppie nodo-peso \verb|v| adiacenti a \verb|u.second| (nodo restituito dall'operazione \verb|extractMin|).
	\lstset{language=c++, style=mystyle, firstnumber=13}  	 	
	\begin{lstlisting}[mathescape=true]
	std::pair<W, int> u = Q.extractMin();
	for(std::pair<int, W> v: G[u.second]){\end{lstlisting}
	
	Per l'aggiornamento dei vettori $\pi$ e \textit{key} all'interno del ciclo:
	\lstset{language=c++, style=mystyle,backgroundcolor=\color{white}, firstnumber=10}  	 	
	\begin{lstlisting}[mathescape=true]
	if v $\in$ Q and w(u,v) $<$ key[v] {
		$\pi$[v] $\gets$ u;
		key[v] $\gets$ w(u,v);
	}\end{lstlisting}
	Si ricava il valore di $w(u,v)$ dalla coppia \verb|v| estratta dalla lista di adiacenza e il valore di \textit{key} dalla lista \verb|V|. La presenza di \verb|v.first| nel MinHeap è controllata usando il metodo \verb|exists|.\\
	Utilizzando il metodo \verb|decreaseUpdate| si aggiorna il valore di \textit{key} all'interno del MinHeap e successivamente si aggiornano anche \verb|V| (in modo da mantenere la coerenza tra heap e valore di cui viene fatto il check prima di ogni update) e \verb|pi|.
	\lstset{language=c++, style=mystyle, firstnumber=15}
	\begin{lstlisting}
	if(Q.exists(v.first) && v.second < V[v.first].first){
		Q.decreaseUpdate(v.second, v.first);
		V[v.first].first = v.second;
		pi[v.first] = u.second;
	}\end{lstlisting}
	
	Infine, per fare il \verb|return| del MST:
	\lstset{language=c++, style=mystyle,backgroundcolor=\color{white}, firstnumber=16}  	 	
	\begin{lstlisting}[mathescape=true]
	return A;\end{lstlisting}
	La costruzione è implicita ed è rappresentata dall'albero creato da $\pi$, con i pesi memorizzati in \textit{key}.\\
	Per esigenze di uniformità con gli altri algoritmi, tale costruzione viene esplicitata costruendo una \textbf{AdjacencyList$<$W$>$} che rappresenta il MST. Questa costruzione viene fatta in tempo $O(n)$ e quindi non cambia la complessità asintotica dell'algoritmo. 
	\lstset{language=c++, style=mystyle, firstnumber=22}
	\begin{lstlisting}
	AdjacencyList<W> A(n_vec);
	for(unsigned int i = 0; i < n_vec; ++i){
		if(pi[i] != -1 && pi[i] != i)
			A.add(Edge(i, pi[i], V[i].first));
	}
	return A;\end{lstlisting}
\end{flushleft}
\subsubsection{Naive Kruskal}
\begin{flushleft}
Abbiamo implementato l'algoritmo in due versioni diverse presenti nei file \verb|algorithms\kruskal_naive_bfs.h| e \verb|algorithms\kruskal_naive_dfs.h|, l'unica differenza tra le due implementazioni è l'approccio alla \textit{cycle detection} in fase di costruzione del MST, di seguito andremmo ad analizzare la versione che utilizza \textbf{DFS}:

\lstset{language=c++, style=mystyle}
\lstinputlisting[language=c++]{k_naive.cpp}

\textbf{Note implementative:}

\medskip
Per l'ordinamento della lista di lati:

\lstset{language=c++, style=mystyle,backgroundcolor=\color{white}, firstnumber=2}  	 	
\begin{lstlisting}
sort edges of G by cost
\end{lstlisting}

\smallskip
si è utilizzata la funzione \verb|std::sort()| che assicura l'ordinamento in tempo $O(m\cdot\log n)$, è stato necessario ridefinire l'operatore di minimo \textbf{$<$} nella classe \textbf{Edge$<$W$>$}
 
\lstset{language=c++, style=mystyle, firstnumber=3} 	 	
\begin{lstlisting}
std::sort(E.begin(), E.end());
\end{lstlisting}

\medskip
Per il controllo dell'aciclicità nel caso di aggiunta di un nuovo lato:

\lstset{language=c++, style=mystyle,backgroundcolor=\color{white}, firstnumber=4}  	 	
\begin{lstlisting}
if A U {e} is acyclic then
\end{lstlisting}

\smallskip
sono stati implementati sia l'algoritmo ricorsivo DFS che l'algoritmo iterativo BFS, queste due funzioni sono state ottimizzate in modo tale che ritornino TRUE solo se esiste già un cammino tra i nodi adiacenti al lato che stiamo analizzando.

Se ritornano FALSE allora possiamo aggiungere il nuovo lato alla lista di adiacenza con la certezza che non verrà a formarsi un ciclo.

\lstset{language=c++, style=mystyle, firstnumber=5}
\begin{lstlisting}
if(!A.DFS(E[i].get_node_1(), E[i].get_node_2()))
\end{lstlisting}

\medskip
Inoltre si è ottimizzato l'algoritmo con un controllo addizionale per far terminare anticipatamente l'iterazione, controllando che il numero di lati non sia mai maggiore o uguale al numero di nodi del grafo.

\lstset{language=c++, style=mystyle, firstnumber=7}
\begin{lstlisting}
if(A.get_edges() == (A.get_nodes() - 1))
    break;
\end{lstlisting}
\end{flushleft}
\subsubsection{Kruskal (con Union-Find)}
\begin{flushleft}
La nostra implementazione presente nel file \verb|algorithms\kruskal_union_find.h| è la seguente:

\lstset{language=c++, style=mystyle}
\lstinputlisting[language=c++]{k_union.cpp}

\textbf{Note implementative:}

\medskip
Per l'inizializzazione della struttura Union-Find:

\lstset{language=c++, style=mystyle,backgroundcolor=\color{white}, firstnumber=2}  	 	
\begin{lstlisting}
U = initialize(V)
\end{lstlisting}

\smallskip
al costruttore è passato un vettore di interi con valori distinti per far si che inizialmente tutti i nodi appartengano a componenti connesse distinte.

\lstset{language=c++, style=mystyle, firstnumber=3}  	 	
\begin{lstlisting}
int *V;
V = new int[n_vec];
std::iota(V, V + n, 0);
UnionFind U(V, n_vec);
\end{lstlisting}

\medskip
Per l'ordinamento della lista di lati:

\lstset{language=c++, style=mystyle,backgroundcolor=\color{white}, firstnumber=2}  	 	
\begin{lstlisting}
sort edges of G by cost
\end{lstlisting}

\smallskip
si è utilizzata la funzione \verb|std::sort()| che assicura l'ordinamento in tempo $O(m\cdot\log n)$ 
, è stato necessario ridefinire l'operatore di minimo \textbf{$<$} nella classe \textbf{Edge$<$W$>$}
 
\lstset{language=c++, style=mystyle, firstnumber=7} 	 	
\begin{lstlisting}
std::sort(E.begin(), E.end());
\end{lstlisting}

\medskip
Per controllare se due nodi appartengono alla stessa componente connessa e per unire le componenti connesse
\lstset{language=c++, style=mystyle,backgroundcolor=\color{white}, firstnumber=2}  	 	
\begin{lstlisting}
if Find(U,v) =/= Find(U,w) then
	A = A U (v,w)
	Union(U,v,w)
\end{lstlisting}

\smallskip
sono state implementate le funzioni \verb|U.find()| e \verb|U.unite|.

\lstset{language=c++, style=mystyle, firstnumber=9} 	 	
\begin{lstlisting}
if (U.find(e.get_node_1()) != U.find(e.get_node_2())) {
	A.add(e);
    U.unite(e.get_node_1(), e.get_node_2());
}
\end{lstlisting}

\medskip
Inoltre si è ottimizzato l'algoritmo con un controllo addizionale per far terminare anticipatamente l'iterazione, controllando che il numero di lati non sia mai maggiore o uguale al numero di nodi del grafo.

\lstset{language=c++, style=mystyle, firstnumber=13}
\begin{lstlisting}
if(A.get_edges() == (A.get_nodes() - 1))
    break;
\end{lstlisting}
\end{flushleft}
\subsection{Note su compilazione}
Per il progetto è stato utilizzato il build-system CMake. Per generare il makefile è necessario disporre di una versione di tale software $\geq 3.14$ e per la compilazione è necessario un compilatore che supporti lo standard 2017 del linguaggio C++.
\newpage
\section{Testing e analisi sperimentali}
\subsection{Risultati prodotti}
\begin{flushleft}
Di seguito è mostrata la tabella completa dei tempi di esecuzione (ignorando il tempo utilizzato per il parsing) degli algoritmi per ogni grafo e relativo peso del MST: 
\input{time.tex}

La tabella di seguito mostra la media dei tempi di esecuzione di ogni algoritmo fra istanze di grafi del dataset con lo stesso numero di nodi.\\
Tale tabella serve a chiarire la relazione tra taglia del grafo e tempi di esecuzione a prescindere dall'istanza specifica di esecuzione dei vari algoritmi.
\input{time_mean.tex}
\newpage
\subsection{Analisi e conclusioni}
Dall'analisi dei tempi d'esecuzione possiamo notare che generalmente gli algoritmi considerati più efficienti (quelli con complessità asintotica $O(m\cdot\log n)$) risultano essere effettivamente i più veloci.\\
Si può infatti notare dalla Figura \ref{total} come il tempo totale di esecuzione dell'algoritmo di Prim e Kruskal Union-Find sull'intero test-set ammonti a pochi secondi ($\leq 5 s$) mentre le varie istanze di Naive Kruskal impieghino dai 20 ai 30 minuti.
\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{grafo_costo_totale.png}
	\caption{\textbf{Tempo di esecuzione totale}}
	\label{total}
\end{figure}

\newpage
\subsubsection{Confronto tra tutti gli algoritmi}
Considerando invece i tempi di esecuzione medi in relazione al numero di nodi di un grafo, ci accorgiamo che, per grafi di piccola taglia, le varianti DFS e BFS di Naive Kruskal risultano essere più efficienti di Prim.\\
Come si può notare dalla Figura \ref{conf_tot}, Kruskal DFS e Kruskal BFS hanno tempi medi d'esecuzione più bassi rispetto all'algoritmo di Prim per grafi con numero di nodi, rispettivamente, minori di 100 e 40.
Questo fenomeno è probabilmente dovuto all'overhead causato dall'utilizzo di strutture dati come MinHeap e dalla costruzione della AdjacencyList finale che diventa tuttavia trascurabile per grafi di taglia sufficientemente alta ed è compensato dai benefici che esse forniscono in termini di efficienza.\\
Notiamo inoltre che Kruskal con Union-Find è l'algoritmo più efficiente e riesce ad ottenere prestazioni migliori rispetto agli altri algoritmi su grafi di qualsiasi taglia.\\
\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{CONFRONTO_TOTALE.png}
	\caption{\textbf{Confronto tra algoritmi su tempi d'esecuzione medi misurati su grafi della stessa taglia}}
	\label{conf_tot}
\end{figure}
Notiamo infine un caso particolare per i grafi di taglia 100 nella quale tutti gli algoritmi sembrano avere un tempo di esecuzione simile, osservando i singoli grafi possiamo notare come il grafo 20 risulti l'unico in cui \textbf{KRUSKAL UNION-FIND} abbia un tempo di esecuzione peggiore di tutte le altre implementazioni.

%\begin{figure}[h]
%	\centering
%	\includegraphics[width=0.5\textwidth,height=0.2\textheight,keepaspectratio]{grafo_20.png}\%\caption{\textbf{Rappresentazione senza lati pesati del grafo 20}}
%	\label{grafo_20}
%\end{figure}

%\begin{figure}[h]
%\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{PRIM_MEDIA.png}
%\caption{\textbf{PRIM}}

%possiamo osservare che prim fa robe
%\end{figure}

%\begin{figure}[h]
%\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{K_UNION_MEDIA.png}
%\caption{\textbf{KRUSKAL UNION-FIND}}

%possiamo osservare che union find è leggermente più lento di prim
%\end{figure}

%\begin{figure}[h]

%\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{K_DFS_MEDIA.png}
%\caption{\textbf{KRUSKAL DFS}}

%possiamo osservare che dfs non è molto buono
%\end{figure}

%\begin{figure}[h]

%\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{K_BFS_MEDIA.png}
%\caption{\textbf{KRUSKAL BFS}}

%possiamo osservare che BFS è il peggiore
%\end{figure}
\newpage
\subsubsection{Confronto tra le varianti di Naive Kruskal}
Le due varianti di Naive Kruskal differiscono unicamente nell'approccio alla \textit{cycle detection} in fase di costruzione del MST. Adottando un approccio naive al problema è possibile scegliere un qualsiasi algoritmo di ricerca su grafo per capire se tra due vertici esiste un percorso che li collega. Abbiamo perciò ritenuto interessante esplorare due possibili varianti in modo da poter scegliere la più efficiente.\\
Come mostrato in Figura \ref{dfs-bfs}, indipendentemente dalla variante selezionata, i tempi d'esecuzione sono molto simili tra loro per grafi con numero di nodi inferiore a 20.000. Tuttavia, per grafi di taglia superiore, diventa chiara la superiorità di DFS rispetto a BFS e la differenza tra i tempi di esecuzione raggiunge approssimativamente il minuto e mezzo per i grafi con 100.000 nodi.\\
Ciò è probabilmente dovuto alla topologia dei grafi del test set che, essendo generalmente non densi (i.e. $m \ll n(n-1)/2$), richiedono molto spesso visite in profondità per trovare un percorso tra due nodi in caso la condizione di ciclicità sia verificata.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth,height=\textheight,keepaspectratio]{COMPARE_2.png}
	\caption{\textbf{Confronto KRUSKAL DFS e BFS}}
	\label{dfs-bfs}
\end{figure}
\newpage
\subsubsection{Confronto tra Prim e Kruskal Union-Find}
Come affermato in precedenza, Kruskal Union-Find è l'algoritmo più veloce su ogni singola istanza presente nel test-set. Tuttavia la differenza tra esso e Prim, come mostrato in Figura \ref{prim-uf}, diventa significativa solo per grafi di taglia superiore a 1000 nodi, pur rimanendo nello stesso ordine di grandezza. In ogni caso, sia per Prim che per Kruskal Union-Find, i tempi d'esecuzione per una singola istanza rimangono sotto il secondo (il tempo massimo raggiunto da Prim è 0.32s).
\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth,height=\textheight,keepaspectratio]{COMPARE_1.png}
\caption{\textbf{Confronto PRIM e KRUSKAL Union-Find}}
\label{prim-uf}
\end{figure}
\end{flushleft}
\end{document}          
